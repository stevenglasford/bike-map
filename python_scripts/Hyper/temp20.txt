# Enhanced batch processing functions for your existing matcher50.py

class EnhancedTemporalMatchingConfig:
“”“Add this configuration class to your existing config section”””

```
# Duration filtering parameters
MIN_DURATION_RATIO = 0.7  # GPX must be at least 70% of video duration
MAX_DURATION_RATIO = 2.0  # GPX can be at most 200% of video duration
MIN_ABSOLUTE_DURATION = 5.0  # Minimum 5 seconds for both video and GPX

# Temporal quality thresholds
EXCELLENT_DURATION_RATIO_RANGE = (0.85, 1.15)  # Within 15% is excellent
GOOD_DURATION_RATIO_RANGE = (0.75, 1.35)       # Within 25% is good
FAIR_DURATION_RATIO_RANGE = (0.65, 1.5)        # Within 50% is fair

# Advanced filtering
ENABLE_STRICT_DURATION_FILTERING = True
ENABLE_DURATION_WEIGHTED_SCORING = True
```

# Add these methods to your existing TurboCorrelationEngine class

def _pre_filter_gpx_by_duration(self, gps_features_dict: Dict, video_duration: float) -> List[str]:
“”“Pre-filter GPX files based on duration compatibility for efficiency”””

```
if video_duration <= 0:
    return list(gps_features_dict.keys())  # No filtering if video duration unknown

temporal_config = EnhancedTemporalMatchingConfig()
compatible_paths = []

min_gpx_duration = video_duration * temporal_config.MIN_DURATION_RATIO
max_gpx_duration = video_duration * temporal_config.MAX_DURATION_RATIO

total_gps = len(gps_features_dict)
filtered_count = 0

for gps_path, gps_data in gps_features_dict.items():
    if gps_data is None:
        continue
        
    gps_duration = gps_data.get('duration', 0)
    
    # Apply minimum absolute duration filter
    if gps_duration < temporal_config.MIN_ABSOLUTE_DURATION:
        filtered_count += 1
        continue
        
    # Apply duration ratio filters
    if temporal_config.ENABLE_STRICT_DURATION_FILTERING:
        if gps_duration < min_gpx_duration or gps_duration > max_gpx_duration:
            filtered_count += 1
            continue
    
    compatible_paths.append(gps_path)

logger.info(f"Duration filtering: {len(compatible_paths)}/{total_gps} GPX files compatible "
           f"with video duration {video_duration:.1f}s (filtered {filtered_count})")

return compatible_paths
```

def _assess_duration_compatibility(self, video_duration: float, gpx_duration: float) -> Dict:
“”“Assess temporal compatibility between video and GPX files”””

```
temporal_config = EnhancedTemporalMatchingConfig()

# Handle edge cases
if video_duration <= 0 or gpx_duration <= 0:
    return {
        'is_compatible': False,
        'reason': 'invalid_duration',
        'ratio': 0.0,
        'temporal_quality': 'invalid',
        'duration_score': 0.0
    }

# Calculate duration ratio (GPX duration / Video duration)
duration_ratio = gpx_duration / video_duration

# Check minimum duration requirements
if (video_duration < temporal_config.MIN_ABSOLUTE_DURATION or 
    gpx_duration < temporal_config.MIN_ABSOLUTE_DURATION):
    return {
        'is_compatible': False,
        'reason': 'below_minimum_duration',
        'ratio': duration_ratio,
        'temporal_quality': 'too_short',
        'duration_score': 0.0
    }

# Apply strict duration filtering if enabled
if temporal_config.ENABLE_STRICT_DURATION_FILTERING:
    if (duration_ratio < temporal_config.MIN_DURATION_RATIO or 
        duration_ratio > temporal_config.MAX_DURATION_RATIO):
        return {
            'is_compatible': False,
            'reason': 'duration_ratio_out_of_bounds',
            'ratio': duration_ratio,
            'temporal_quality': 'incompatible',
            'duration_score': 0.0
        }

# Assess temporal quality level
temporal_quality = self._assess_temporal_quality(duration_ratio)
duration_score = self._calculate_duration_score(duration_ratio)

return {
    'is_compatible': True,
    'ratio': duration_ratio,
    'temporal_quality': temporal_quality,
    'video_duration': video_duration,
    'gpx_duration': gpx_duration,
    'duration_score': duration_score
}
```

def _assess_temporal_quality(self, duration_ratio: float) -> str:
“”“Assess the quality of temporal match based on duration ratio”””

```
temporal_config = EnhancedTemporalMatchingConfig()

excellent_range = temporal_config.EXCELLENT_DURATION_RATIO_RANGE
good_range = temporal_config.GOOD_DURATION_RATIO_RANGE
fair_range = temporal_config.FAIR_DURATION_RATIO_RANGE

if excellent_range[0] <= duration_ratio <= excellent_range[1]:
    return 'excellent'
elif good_range[0] <= duration_ratio <= good_range[1]:
    return 'good'
elif fair_range[0] <= duration_ratio <= fair_range[1]:
    return 'fair'
else:
    return 'poor'
```

def _calculate_duration_score(self, duration_ratio: float) -> float:
“”“Calculate a normalized score (0-1) based on duration ratio”””

```
# Optimal ratio is 1.0 (GPX and video same duration)
optimal_ratio = 1.0

# Calculate distance from optimal ratio
ratio_distance = abs(duration_ratio - optimal_ratio)

# Convert to score using exponential decay
duration_score = np.exp(-2 * ratio_distance)

return float(np.clip(duration_score, 0.0, 1.0))
```

def _apply_duration_scoring(self, base_score: float, duration_compatibility: Dict) -> Dict:
“”“Apply duration-aware scoring to base correlation score”””

```
temporal_config = EnhancedTemporalMatchingConfig()

if not temporal_config.ENABLE_DURATION_WEIGHTED_SCORING:
    return {
        'combined_score': base_score,
        'quality': self._assess_quality(base_score),
        'duration_info': duration_compatibility
    }

duration_score = duration_compatibility['duration_score']
temporal_quality = duration_compatibility['temporal_quality']

# Calculate duration weight based on temporal quality
duration_weights = {
    'excellent': 1.0,      # No penalty
    'good': 0.95,          # 5% penalty
    'fair': 0.85,          # 15% penalty
    'poor': 0.7,           # 30% penalty
}

duration_weight = duration_weights.get(temporal_quality, 0.5)

# Apply duration weighting
enhanced_score = base_score * duration_weight

# Add duration bonus for excellent temporal matches
if temporal_quality == 'excellent' and base_score > 0.6:
    duration_bonus = duration_score * 0.1  # Up to 10% bonus
    enhanced_score = min(enhanced_score + duration_bonus, 1.0)

# Enhanced quality assessment
enhanced_quality = self._assess_enhanced_quality(
    enhanced_score, temporal_quality, duration_compatibility['ratio']
)

return {
    'combined_score': enhanced_score,
    'quality': enhanced_quality,
    'duration_info': duration_compatibility,
    'duration_score': duration_score,
    'temporal_quality': temporal_quality
}
```

def _assess_enhanced_quality(self, combined_score: float, temporal_quality: str, duration_ratio: float) -> str:
“”“Enhanced quality assessment considering both correlation and temporal factors”””

```
# Base quality from correlation score
if combined_score >= 0.85:
    base_quality = 'excellent'
elif combined_score >= 0.70:
    base_quality = 'very_good'
elif combined_score >= 0.55:
    base_quality = 'good'
elif combined_score >= 0.40:
    base_quality = 'fair'
elif combined_score >= 0.25:
    base_quality = 'poor'
else:
    base_quality = 'very_poor'

# Quality degradation based on temporal mismatch
temporal_penalties = {
    'excellent': 0,    # No degradation
    'good': 0,         # No degradation
    'fair': 1,         # Downgrade by 1 level
    'poor': 2,         # Downgrade by 2 levels
}

quality_levels = ['very_poor', 'poor', 'fair', 'good', 'very_good', 'excellent']
base_index = quality_levels.index(base_quality)
penalty = temporal_penalties.get(temporal_quality, 3)

# Apply penalty
final_index = max(0, base_index - penalty)
final_quality = quality_levels[final_index]

# Additional check for severe duration mismatches
if duration_ratio < 0.3 or duration_ratio > 3.0:
    # Extreme duration mismatch - cap at 'poor' maximum
    final_quality = 'poor' if final_quality in ['very_good', 'excellent'] else final_quality

return final_quality
```

def _create_gps_batches(self, gps_paths: List[str], batch_size: int = 32) -> List[List[str]]:
“”“Create batches of GPS paths for efficient processing”””

```
batches = []
for i in range(0, len(gps_paths), batch_size):
    batch = gps_paths[i:i + batch_size]
    batches.append(batch)

return batches
```

def _log_duration_analysis_results(self, video_path: str, matches: List[Dict], video_duration: float):
“”“Log duration analysis results for debugging and monitoring”””

```
if not matches:
    logger.warning(f"No valid matches found for {video_path} (duration: {video_duration:.1f}s)")
    return

# Analyze match quality distribution
quality_counts = {}
temporal_quality_counts = {}
duration_ratios = []

for match in matches:
    quality = match.get('quality', 'unknown')
    temporal_quality = match.get('temporal_quality', 'unknown')
    duration_ratio = match.get('duration_ratio', 0)
    
    quality_counts[quality] = quality_counts.get(quality, 0) + 1
    temporal_quality_counts[temporal_quality] = temporal_quality_counts.get(temporal_quality, 0) + 1
    if duration_ratio > 0:
        duration_ratios.append(duration_ratio)

# Log summary
best_match = matches[0]
logger.info(f"Duration analysis for {os.path.basename(video_path)}:")
logger.info(f"  Video duration: {video_duration:.1f}s")
logger.info(f"  Best match: {best_match.get('duration', 0):.1f}s "
           f"(ratio: {best_match.get('duration_ratio', 0):.2f}, "
           f"quality: {best_match.get('quality', 'unknown')}, "
           f"temporal: {best_match.get('temporal_quality', 'unknown')})")
logger.info(f"  Total matches: {len(matches)}")
logger.info(f"  Quality distribution: {quality_counts}")

if duration_ratios:
    logger.info(f"  Duration ratio stats: min={min(duration_ratios):.2f}, "
               f"max={max(duration_ratios):.2f}, "
               f"mean={np.mean(duration_ratios):.2f}")
```

# REPLACE your existing _process_batch_standard_gpu function with this enhanced version:

def _process_batch_standard_gpu(self, video_batch_paths: List[str], video_features_dict: Dict,
gps_paths: List[str], gps_features_dict: Dict,
device: torch.device, model: nn.Module) -> Dict:
“”“Enhanced standard batch processing with duration filtering”””
batch_results = {}

```
for video_path in video_batch_paths:
    video_features = video_features_dict[video_path]
    if video_features is None:
        batch_results[video_path] = {'matches': []}
        continue
    
    matches = []
    
    # Extract video duration for filtering
    video_duration = video_features.get('duration', 0.0)
    
    # ENHANCEMENT: Pre-filter GPX files by duration compatibility
    if video_duration > 0:
        compatible_gps_paths = self._pre_filter_gpx_by_duration(gps_features_dict, video_duration)
        if not compatible_gps_paths:
            logger.debug(f"No temporally compatible GPX files for video {os.path.basename(video_path)} "
                       f"(duration: {video_duration:.1f}s)")
            batch_results[video_path] = {'matches': []}
            continue
    else:
        # Fallback to all GPS files if video duration is unknown
        compatible_gps_paths = gps_paths
        logger.warning(f"Video duration unknown for {os.path.basename(video_path)}, "
                     f"processing all {len(compatible_gps_paths)} GPX files")
    
    # Prepare video feature tensor
    video_tensor = self._features_to_tensor(video_features, device)
    if video_tensor is None:
        batch_results[video_path] = {'matches': []}
        continue
    
    # Process GPS files in sub-batches using only compatible GPX files
    gps_batch_size = min(64, len(compatible_gps_paths))  # Larger sub-batches for speed
    
    for gps_start in range(0, len(compatible_gps_paths), gps_batch_size):
        gps_end = min(gps_start + gps_batch_size, len(compatible_gps_paths))
        gps_batch_paths = compatible_gps_paths[gps_start:gps_end]
        
        # Prepare GPS batch tensors
        gps_tensors = []
        valid_gps_paths = []
        
        for gps_path in gps_batch_paths:
            gps_data = gps_features_dict[gps_path]
            if gps_data and 'features' in gps_data:
                gps_tensor = self._features_to_tensor(gps_data['features'], device)
                if gps_tensor is not None:
                    gps_tensors.append(gps_tensor)
                    valid_gps_paths.append(gps_path)
        
        if not gps_tensors:
            continue
        
        # Stack tensors for batch processing with size standardization
        try:
            # PRESERVED: Your existing tensor standardization logic
            standardized_gps_tensors = []
            target_length = 512  # Standard sequence length
            
            for gps_tensor in gps_tensors:
                # Standardize each tensor to the same size
                if gps_tensor.size(0) != target_length:
                    # Interpolate to target length
                    gps_tensor_reshaped = gps_tensor.transpose(0, 1).unsqueeze(0)  # [1, features, sequence]
                    gps_tensor_interpolated = F.interpolate(
                        gps_tensor_reshaped, 
                        size=target_length, 
                        mode='linear', 
                        align_corners=False
                    )
                    gps_tensor = gps_tensor_interpolated.squeeze(0).transpose(0, 1)  # [sequence, features]
                
                # Ensure consistent feature dimension
                if gps_tensor.size(-1) < 4:
                    padding_size = 4 - gps_tensor.size(-1)
                    padding = torch.zeros(gps_tensor.size(0), padding_size, device=device)
                    gps_tensor = torch.cat([gps_tensor, padding], dim=-1)
                elif gps_tensor.size(-1) > 4:
                    gps_tensor = gps_tensor[:, :4]
                
                standardized_gps_tensors.append(gps_tensor)
            
            # Now stacking will work because all tensors have the same size
            gps_batch_tensor = torch.stack(standardized_gps_tensors).to(device, non_blocking=True)
            
            # Also standardize video tensor to match
            if video_tensor.size(0) != target_length:
                video_tensor_reshaped = video_tensor.transpose(0, 1).unsqueeze(0)
                video_tensor_interpolated = F.interpolate(
                    video_tensor_reshaped, 
                    size=target_length, 
                    mode='linear', 
                    align_corners=False
                )
                video_tensor = video_tensor_interpolated.squeeze(0).transpose(0, 1)
            
            # Ensure video tensor has consistent feature dimension
            if video_tensor.size(-1) < 4:
                padding_size = 4 - video_tensor.size(-1)
                padding = torch.zeros(video_tensor.size(0), padding_size, device=device)
                video_tensor = torch.cat([video_tensor, padding], dim=-1)
            elif video_tensor.size(-1) > 4:
                video_tensor = video_tensor[:, :4]
            
            video_batch_tensor = video_tensor.unsqueeze(0).repeat(len(standardized_gps_tensors), 1, 1)
            
            # Compute batch correlations
            correlation_scores = model(video_batch_tensor, gps_batch_tensor)
            correlation_scores = correlation_scores.cpu().numpy()
                                
            # ENHANCEMENT: Create match entries with duration-aware scoring
            for i, (gps_path, score) in enumerate(zip(valid_gps_paths, correlation_scores)):
                gps_data = gps_features_dict[gps_path]
                gps_duration = gps_data.get('duration', 0)
                
                # Assess duration compatibility
                duration_compatibility = self._assess_duration_compatibility(video_duration, gps_duration)
                
                # Apply duration-aware scoring
                enhanced_scoring = self._apply_duration_scoring(float(score), duration_compatibility)
                
                match_info = {
                    'path': gps_path,
                    'combined_score': enhanced_scoring['combined_score'],
                    'quality': enhanced_scoring['quality'],
                    'distance': gps_data.get('distance', 0),
                    'duration': gps_duration,
                    'video_duration': video_duration,
                    'duration_ratio': gps_duration / video_duration if video_duration > 0 else 0,
                    'temporal_quality': enhanced_scoring.get('temporal_quality', 'unknown'),
                    'duration_score': enhanced_scoring.get('duration_score', 0.0),
                    'avg_speed': gps_data.get('avg_speed', 0),
                    'processing_mode': 'EnhancedTurboGPU_DurationFiltered',
                    'confidence': enhanced_scoring['combined_score'],
                    'is_360_video': video_features.get('is_360_video', False),
                    'original_score': float(score)  # Keep original for debugging
                }
                matches.append(match_info)
        
        except Exception as e:
            logger.debug(f"Enhanced batch correlation failed: {e}")
            # Fallback to individual processing with duration info
            for gps_path in valid_gps_paths:
                gps_data = gps_features_dict[gps_path]
                match_info = {
                    'path': gps_path,
                    'combined_score': 0.0,
                    'quality': 'failed',
                    'error': str(e),
                    'duration': gps_data.get('duration', 0),
                    'video_duration': video_duration,
                    'processing_mode': 'EnhancedTurboGPU_Fallback'
                }
                matches.append(match_info)
    
    # Sort matches by enhanced score
    matches.sort(key=lambda x: x['combined_score'], reverse=True)
    
    # Log duration analysis results
    self._log_duration_analysis_results(video_path, matches, video_duration)
    
    batch_results[video_path] = {'matches': matches}

return batch_results
```

# OPTIONAL: Command line argument integration

def add_duration_filtering_arguments(parser):
“”“Add these arguments to your existing argument parser”””

```
duration_group = parser.add_argument_group('Duration Filtering Options')

duration_group.add_argument(
    '--min-duration-ratio', 
    type=float, 
    default=0.7,
    help='Minimum GPX duration as ratio of video duration (default: 0.7)'
)

duration_group.add_argument(
    '--max-duration-ratio', 
    type=float, 
    default=2.0,
    help='Maximum GPX duration as ratio of video duration (default: 2.0)'
)

duration_group.add_argument(
    '--min-absolute-duration', 
    type=float, 
    default=5.0,
    help='Minimum absolute duration in seconds for both video and GPX (default: 5.0)'
)

duration_group.add_argument(
    '--disable-duration-filtering', 
    action='store_true',
    help='Disable duration-based filtering (not recommended)'
)
```

# Configuration integration example

def update_temporal_config_from_args(args):
“”“Update temporal configuration from command line arguments”””

```
if hasattr(args, 'min_duration_ratio'):
    EnhancedTemporalMatchingConfig.MIN_DURATION_RATIO = args.min_duration_ratio

if hasattr(args, 'max_duration_ratio'):
    EnhancedTemporalMatchingConfig.MAX_DURATION_RATIO = args.max_duration_ratio

if hasattr(args, 'min_absolute_duration'):
    EnhancedTemporalMatchingConfig.MIN_ABSOLUTE_DURATION = args.min_absolute_duration

if hasattr(args, 'disable_duration_filtering'):
    EnhancedTemporalMatchingConfig.ENABLE_STRICT_DURATION_FILTERING = not args.disable_duration_filtering

logger.info(f"Duration filtering config: "
           f"ratio range [{EnhancedTemporalMatchingConfig.MIN_DURATION_RATIO:.1f}, "
           f"{EnhancedTemporalMatchingConfig.MAX_DURATION_RATIO:.1f}], "
           f"min duration {EnhancedTemporalMatchingConfig.MIN_ABSOLUTE_DURATION:.1f}s, "
           f"strict filtering {'enabled' if EnhancedTemporalMatchingConfig.ENABLE_STRICT_DURATION_FILTERING else 'disabled'}")
```

print(“Enhanced batch processing ready for integration!”)
print(”\n✅ Key Integration Steps:”)
print(“1. Add EnhancedTemporalMatchingConfig class”)
print(“2. Add all the helper methods to your TurboCorrelationEngine class”)
print(“3. Replace your _process_batch_standard_gpu function with the enhanced version”)
print(“4. Optionally add command line arguments for duration filtering”)
print(”\n🚀 Expected Results:”)
print(”- 6-second GPX files will be filtered out before GPU processing”)
print(”- Remaining matches will have duration-aware quality scores”)
print(”- Detailed logging will show filtering statistics”)
print(”- Performance will improve due to pre-filtering”)